{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "X = []\n",
    "with open(\"./data/train/crawler/data/tweets.txt.text\", newline='', encoding='utf8') as file_data:\n",
    "    i = 0 \n",
    "    for row in file_data:\n",
    "        if i < 500:\n",
    "            i = i +1\n",
    "            X.append(row)\n",
    "\n",
    "y = []\n",
    "with open(\"./data/train/crawler/data/tweets.txt.labels\", newline='', encoding='utf8') as file_data:\n",
    "    j = 0\n",
    "    for row in file_data:\n",
    "        if j < 500:\n",
    "            j = j +1\n",
    "            y.append(row.replace(\"\\n\",\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "X_dtm = vect.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=[]\n",
    "with open(\"./data/test/us_test.text\", newline='', encoding='utf8') as test_data:\n",
    "    file = test_data.readlines()\n",
    "    for row in file:\n",
    "        test.append(row.replace(\"\\n\",\"\"))\n",
    "test = np.asarray(test)\n",
    "test_dtm = vect.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = []\n",
    "with open(\"./data/test/us_test.labels\", newline='', encoding='utf8') as test_data_label:\n",
    "    file = test_data_label.readlines()\n",
    "    for row in file:\n",
    "        test_label.append(row.replace(\"\\n\",\"\"))\n",
    "test_label = np.asarray(test_label)\n",
    "test_label = test_label.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.63      0.36     10798\n",
      "           1       0.12      0.12      0.12      4830\n",
      "          10       0.06      0.02      0.03      1432\n",
      "          11       0.15      0.03      0.05      1949\n",
      "          12       0.18      0.04      0.06      1265\n",
      "          13       0.04      0.00      0.01      1114\n",
      "          14       0.05      0.01      0.01      1306\n",
      "          15       0.07      0.00      0.00      1244\n",
      "          16       0.01      0.00      0.00      1153\n",
      "          17       0.71      0.37      0.48      1545\n",
      "          18       0.17      0.02      0.03      2417\n",
      "          19       0.00      0.00      0.00      1010\n",
      "           2       0.15      0.28      0.20      4534\n",
      "           3       0.09      0.05      0.07      2605\n",
      "           4       0.23      0.16      0.19      3716\n",
      "           5       0.06      0.04      0.05      1613\n",
      "           6       0.05      0.01      0.01      1996\n",
      "           7       0.14      0.00      0.00      2749\n",
      "           8       0.06      0.02      0.03      1549\n",
      "           9       0.04      0.03      0.04      1175\n",
      "\n",
      "    accuracy                           0.20     50000\n",
      "   macro avg       0.13      0.09      0.09     50000\n",
      "weighted avg       0.16      0.20      0.15     50000\n",
      "\n",
      "la matrice de confusion : \n",
      "[[[18724 20478]\n",
      "  [ 4037  6761]]\n",
      "\n",
      " [[40764  4406]\n",
      "  [ 4246   584]]\n",
      "\n",
      " [[48216   352]\n",
      "  [ 1408    24]]\n",
      "\n",
      " [[47751   300]\n",
      "  [ 1897    52]]\n",
      "\n",
      " [[48511   224]\n",
      "  [ 1217    48]]\n",
      "\n",
      " [[48822    64]\n",
      "  [ 1111     3]]\n",
      "\n",
      " [[48521   173]\n",
      "  [ 1296    10]]\n",
      "\n",
      " [[48728    28]\n",
      "  [ 1242     2]]\n",
      "\n",
      " [[48668   179]\n",
      "  [ 1152     1]]\n",
      "\n",
      " [[48226   229]\n",
      "  [  981   564]]\n",
      "\n",
      " [[47382   201]\n",
      "  [ 2377    40]]\n",
      "\n",
      " [[48988     2]\n",
      "  [ 1010     0]]\n",
      "\n",
      " [[38366  7100]\n",
      "  [ 3264  1270]]\n",
      "\n",
      " [[45951  1444]\n",
      "  [ 2463   142]]\n",
      "\n",
      " [[44381  1903]\n",
      "  [ 3132   584]]\n",
      "\n",
      " [[47363  1024]\n",
      "  [ 1549    64]]\n",
      "\n",
      " [[47753   251]\n",
      "  [ 1983    13]]\n",
      "\n",
      " [[47213    38]\n",
      "  [ 2743     6]]\n",
      "\n",
      " [[47999   452]\n",
      "  [ 1520    29]]\n",
      "\n",
      " [[47909   916]\n",
      "  [ 1136    39]]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score, f1_score, jaccard_score, classification_report\n",
    "\n",
    "models = [\n",
    "    LogisticRegression(random_state=0, solver='lbfgs',\n",
    "                          multi_class='multinomial',\n",
    "                        n_jobs=-1, max_iter= 1000)\n",
    "]\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    model.fit(X_dtm, y)\n",
    "    predict_label = model.predict(test_dtm)\n",
    "    acc = accuracy_score(predict_label,test_label)\n",
    "    f1 = f1_score(predict_label, test_label, average = 'weighted')\n",
    "    cm = multilabel_confusion_matrix(test_label,predict_label)\n",
    "    jaccard = jaccard_score(test_label, predict_label, average='micro')\n",
    "    print(classification_report(test_label, predict_label))\n",
    "    print (\"la matrice de confusion : \")\n",
    "    print(cm)\n",
    "    entries.append((model_name, acc, f1, jaccard))\n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'accuracy', 'f1', 'jaccard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           model_name  accuracy        f1   jaccard\n",
      "0  LogisticRegression   0.20472  0.260791  0.114032\n"
     ]
    }
   ],
   "source": [
    "print (cv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/home/julien/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.20850412, 0.64488872, 0.36110107, 0.86796069, 0.34987028,\n",
      "       1.15327382, 0.43410603, 1.43390616, 0.1715188 , 0.88171991,\n",
      "       0.37534825, 1.22245971, 0.38801901, 1.01836991, 0.55536652,\n",
      "       1.2311546 ]), 'std_fit_time': array([0.02219167, 0.03748875, 0.02272539, 0.13014933, 0.00539448,\n",
      "       0.06817575, 0.07801177, 0.20012817, 0.03456551, 0.14927531,\n",
      "       0.06033472, 0.04752019, 0.08604417, 0.17173747, 0.05328032,\n",
      "       0.07199231]), 'mean_score_time': array([0.00069332, 0.00070977, 0.00068974, 0.0006427 , 0.00083105,\n",
      "       0.00107757, 0.00074188, 0.00067385, 0.00075984, 0.00184687,\n",
      "       0.00070278, 0.00712196, 0.00260623, 0.00085282, 0.00074792,\n",
      "       0.00102305]), 'std_score_time': array([9.11064746e-05, 8.17834808e-05, 5.54660213e-05, 4.02178215e-05,\n",
      "       9.68375409e-05, 2.26621956e-04, 1.56191689e-04, 2.94472416e-05,\n",
      "       1.10294988e-04, 1.46504840e-03, 8.47466172e-05, 6.12829924e-03,\n",
      "       2.61180159e-03, 1.95306295e-04, 9.56253696e-06, 4.53741605e-04]), 'param_class_weight': masked_array(data=['balanced', 'balanced', 'balanced', 'balanced',\n",
      "                   'balanced', 'balanced', 'balanced', 'balanced', 'None',\n",
      "                   'None', 'None', 'None', 'None', 'None', 'None', 'None'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_fit_intercept': masked_array(data=[0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_penalty': masked_array(data=['l2', 'l2', 'none', 'none', 'l2', 'l2', 'none', 'none',\n",
      "                   'l2', 'l2', 'none', 'none', 'l2', 'l2', 'none', 'none'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_solver': masked_array(data=['sag', 'newton-cg', 'sag', 'newton-cg', 'sag',\n",
      "                   'newton-cg', 'sag', 'newton-cg', 'sag', 'newton-cg',\n",
      "                   'sag', 'newton-cg', 'sag', 'newton-cg', 'sag',\n",
      "                   'newton-cg'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'class_weight': 'balanced', 'fit_intercept': 0, 'penalty': 'l2', 'solver': 'sag'}, {'class_weight': 'balanced', 'fit_intercept': 0, 'penalty': 'l2', 'solver': 'newton-cg'}, {'class_weight': 'balanced', 'fit_intercept': 0, 'penalty': 'none', 'solver': 'sag'}, {'class_weight': 'balanced', 'fit_intercept': 0, 'penalty': 'none', 'solver': 'newton-cg'}, {'class_weight': 'balanced', 'fit_intercept': 1, 'penalty': 'l2', 'solver': 'sag'}, {'class_weight': 'balanced', 'fit_intercept': 1, 'penalty': 'l2', 'solver': 'newton-cg'}, {'class_weight': 'balanced', 'fit_intercept': 1, 'penalty': 'none', 'solver': 'sag'}, {'class_weight': 'balanced', 'fit_intercept': 1, 'penalty': 'none', 'solver': 'newton-cg'}, {'class_weight': 'None', 'fit_intercept': 0, 'penalty': 'l2', 'solver': 'sag'}, {'class_weight': 'None', 'fit_intercept': 0, 'penalty': 'l2', 'solver': 'newton-cg'}, {'class_weight': 'None', 'fit_intercept': 0, 'penalty': 'none', 'solver': 'sag'}, {'class_weight': 'None', 'fit_intercept': 0, 'penalty': 'none', 'solver': 'newton-cg'}, {'class_weight': 'None', 'fit_intercept': 1, 'penalty': 'l2', 'solver': 'sag'}, {'class_weight': 'None', 'fit_intercept': 1, 'penalty': 'l2', 'solver': 'newton-cg'}, {'class_weight': 'None', 'fit_intercept': 1, 'penalty': 'none', 'solver': 'sag'}, {'class_weight': 'None', 'fit_intercept': 1, 'penalty': 'none', 'solver': 'newton-cg'}], 'split0_test_score': array([0.12138728, 0.12138728, 0.10982659, 0.15028902, 0.13294798,\n",
      "       0.15606936, 0.10404624, 0.13872832, 0.14450867, 0.14450867,\n",
      "       0.13294798, 0.16184971, 0.16184971, 0.19075145, 0.14450867,\n",
      "       0.13872832]), 'split1_test_score': array([0.16167665, 0.16167665, 0.1257485 , 0.16167665, 0.16766467,\n",
      "       0.16167665, 0.13772455, 0.16167665, 0.1497006 , 0.1497006 ,\n",
      "       0.16766467, 0.15568862, 0.1497006 , 0.18562874, 0.15568862,\n",
      "       0.15568862]), 'split2_test_score': array([0.15625, 0.15625, 0.1625 , 0.175  , 0.1625 , 0.1625 , 0.15   ,\n",
      "       0.18125, 0.175  , 0.175  , 0.15   , 0.1875 , 0.175  , 0.1875 ,\n",
      "       0.175  , 0.2    ]), 'mean_test_score': array([0.146, 0.146, 0.132, 0.162, 0.154, 0.16 , 0.13 , 0.16 , 0.156,\n",
      "       0.156, 0.15 , 0.168, 0.162, 0.188, 0.158, 0.164]), 'std_test_score': array([0.01803621, 0.01803621, 0.02192824, 0.01007809, 0.01545408,\n",
      "       0.0028783 , 0.01951907, 0.0173781 , 0.01320846, 0.01320846,\n",
      "       0.01431183, 0.01361588, 0.01022809, 0.00213949, 0.01253961,\n",
      "       0.02566647]), 'rank_test_score': array([13, 13, 15,  4, 11,  6, 16,  6,  9,  9, 12,  2,  4,  1,  8,  3],\n",
      "      dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Test with solver saga\n",
    "parameters_saga = {'penalty':('l2', 'elasticnet', 'none'),\n",
    "              'fit_intercept':[0, 1], 'class_weight':('balanced', 'None'),\n",
    "                  'l1_ratio':[0, 0.5, 1]}\n",
    "lg_saga = LogisticRegression(solver='saga')\n",
    "\n",
    "# Test with solver saga and l1 penalty\n",
    "parameters_saga_l1 = {'fit_intercept':[0, 1], 'class_weight':('balanced', 'None')}\n",
    "lg_saga_l1 = LogisticRegression(solver='saga', penalty='l1')\n",
    "\n",
    "\n",
    "# Test with solver lbfgs\n",
    "parameters_lbfgs = {'penalty':('l2', 'none'), 'fit_intercept':[0, 1],\n",
    "                   'class_weight':('balanced', 'None')}\n",
    "lg_lbfgs = LogisticRegression(solver='lbfgs')\n",
    "\n",
    "\n",
    "parameters = {'solver':('sag', 'newton-cg'), 'penalty':('l2', 'none'),\n",
    "              'fit_intercept':[0, 1], 'class_weight':('balanced', 'None')}\n",
    "lg = LogisticRegression()\n",
    "\n",
    "clf = GridSearchCV(lg, parameters, cv=3, n_jobs=-1)\n",
    "\n",
    "clf.fit(X_dtm, y)\n",
    "                            \n",
    "print(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
