{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "# Training tweets recovery\n",
    "X = []\n",
    "with open(\"./data/train/crawler/data/tweets.txt.text\", newline='', encoding='utf8') as file_data: \n",
    "    for row in file_data:\n",
    "        X.append(row)\n",
    "\n",
    "# Training emojis recovery\n",
    "y = []\n",
    "with open(\"./data/train/crawler/data/tweets.txt.labels\", newline='', encoding='utf8') as file_data:\n",
    "    for row in file_data:\n",
    "        y.append(row.replace(\"\\n\",\"\"))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data vectorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "X_dtm = vect.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data test loading and vectorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing tweets recovery\n",
    "test=[]\n",
    "with open(\"./data/test/us_test.text\", newline='', encoding='utf8') as test_data:\n",
    "    file = test_data.readlines()\n",
    "    for row in file:\n",
    "        test.append(row.replace(\"\\n\",\"\"))\n",
    "test = np.asarray(test)\n",
    "test_dtm = vect.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing emojis recovery\n",
    "test_label = []\n",
    "with open(\"./data/test/us_test.labels\", newline='', encoding='utf8') as test_data_label:\n",
    "    file = test_data_label.readlines()\n",
    "    for row in file:\n",
    "        test_label.append(row.replace(\"\\n\",\"\"))\n",
    "test_label = np.asarray(test_label)\n",
    "test_label = test_label.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model implementation and training\n",
    "## Measurements calculation and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.62      0.44     10798\n",
      "           1       0.24      0.25      0.25      4830\n",
      "          10       0.16      0.14      0.15      1432\n",
      "          11       0.62      0.50      0.56      1949\n",
      "          12       0.35      0.38      0.36      1265\n",
      "          13       0.26      0.06      0.10      1114\n",
      "          14       0.12      0.05      0.07      1306\n",
      "          15       0.24      0.18      0.20      1244\n",
      "          16       0.12      0.05      0.07      1153\n",
      "          17       0.65      0.59      0.62      1545\n",
      "          18       0.31      0.12      0.17      2417\n",
      "          19       0.07      0.03      0.04      1010\n",
      "           2       0.33      0.45      0.38      4534\n",
      "           3       0.15      0.06      0.08      2605\n",
      "           4       0.52      0.42      0.46      3716\n",
      "           5       0.09      0.07      0.08      1613\n",
      "           6       0.18      0.14      0.16      1996\n",
      "           7       0.31      0.18      0.22      2749\n",
      "           8       0.23      0.09      0.13      1549\n",
      "           9       0.13      0.06      0.08      1175\n",
      "\n",
      "    accuracy                           0.32     50000\n",
      "   macro avg       0.27      0.22      0.23     50000\n",
      "weighted avg       0.30      0.32      0.29     50000\n",
      "\n",
      "la matrice de confusion : \n",
      "[[[25842 13360]\n",
      "  [ 4070  6728]]\n",
      "\n",
      " [[41401  3769]\n",
      "  [ 3615  1215]]\n",
      "\n",
      " [[47543  1025]\n",
      "  [ 1238   194]]\n",
      "\n",
      " [[47462   589]\n",
      "  [  968   981]]\n",
      "\n",
      " [[47827   908]\n",
      "  [  785   480]]\n",
      "\n",
      " [[48696   190]\n",
      "  [ 1048    66]]\n",
      "\n",
      " [[48177   517]\n",
      "  [ 1238    68]]\n",
      "\n",
      " [[48066   690]\n",
      "  [ 1024   220]]\n",
      "\n",
      " [[48384   463]\n",
      "  [ 1092    61]]\n",
      "\n",
      " [[47974   481]\n",
      "  [  637   908]]\n",
      "\n",
      " [[46946   637]\n",
      "  [ 2130   287]]\n",
      "\n",
      " [[48595   395]\n",
      "  [  980    30]]\n",
      "\n",
      " [[41291  4175]\n",
      "  [ 2501  2033]]\n",
      "\n",
      " [[46532   863]\n",
      "  [ 2454   151]]\n",
      "\n",
      " [[44820  1464]\n",
      "  [ 2151  1565]]\n",
      "\n",
      " [[47167  1220]\n",
      "  [ 1497   116]]\n",
      "\n",
      " [[46792  1212]\n",
      "  [ 1725   271]]\n",
      "\n",
      " [[46194  1057]\n",
      "  [ 2267   482]]\n",
      "\n",
      " [[47994   457]\n",
      "  [ 1413   136]]\n",
      "\n",
      " [[48358   467]\n",
      "  [ 1106    69]]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score, f1_score, jaccard_score, classification_report\n",
    "\n",
    "models = [\n",
    "    LogisticRegression(random_state=0, solver='lbfgs',\n",
    "                          multi_class='multinomial',\n",
    "                        n_jobs=-1, max_iter= 1000)\n",
    "]\n",
    "\n",
    "# Size of the cross validation \n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    # Training\n",
    "    model.fit(X_dtm, y)\n",
    "    # Prediction\n",
    "    predict_label = model.predict(test_dtm)\n",
    "    # Measurement calculation\n",
    "    acc = accuracy_score(predict_label,test_label)\n",
    "    f1 = f1_score(predict_label, test_label, average = 'weighted')\n",
    "    cm = multilabel_confusion_matrix(test_label,predict_label)\n",
    "    jaccard = jaccard_score(test_label, predict_label, average='micro')\n",
    "    print(classification_report(test_label, predict_label))\n",
    "    print (\"la matrice de confusion : \")\n",
    "    print(cm)\n",
    "    entries.append((model_name, acc, f1, jaccard))\n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'accuracy', 'f1', 'jaccard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           model_name  accuracy        f1   jaccard\n",
      "0  LogisticRegression   0.32122  0.350189  0.191341\n"
     ]
    }
   ],
   "source": [
    "print (cv_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search use to find the best parameters for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/home/julien/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.20850412, 0.64488872, 0.36110107, 0.86796069, 0.34987028,\n",
      "       1.15327382, 0.43410603, 1.43390616, 0.1715188 , 0.88171991,\n",
      "       0.37534825, 1.22245971, 0.38801901, 1.01836991, 0.55536652,\n",
      "       1.2311546 ]), 'std_fit_time': array([0.02219167, 0.03748875, 0.02272539, 0.13014933, 0.00539448,\n",
      "       0.06817575, 0.07801177, 0.20012817, 0.03456551, 0.14927531,\n",
      "       0.06033472, 0.04752019, 0.08604417, 0.17173747, 0.05328032,\n",
      "       0.07199231]), 'mean_score_time': array([0.00069332, 0.00070977, 0.00068974, 0.0006427 , 0.00083105,\n",
      "       0.00107757, 0.00074188, 0.00067385, 0.00075984, 0.00184687,\n",
      "       0.00070278, 0.00712196, 0.00260623, 0.00085282, 0.00074792,\n",
      "       0.00102305]), 'std_score_time': array([9.11064746e-05, 8.17834808e-05, 5.54660213e-05, 4.02178215e-05,\n",
      "       9.68375409e-05, 2.26621956e-04, 1.56191689e-04, 2.94472416e-05,\n",
      "       1.10294988e-04, 1.46504840e-03, 8.47466172e-05, 6.12829924e-03,\n",
      "       2.61180159e-03, 1.95306295e-04, 9.56253696e-06, 4.53741605e-04]), 'param_class_weight': masked_array(data=['balanced', 'balanced', 'balanced', 'balanced',\n",
      "                   'balanced', 'balanced', 'balanced', 'balanced', 'None',\n",
      "                   'None', 'None', 'None', 'None', 'None', 'None', 'None'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_fit_intercept': masked_array(data=[0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_penalty': masked_array(data=['l2', 'l2', 'none', 'none', 'l2', 'l2', 'none', 'none',\n",
      "                   'l2', 'l2', 'none', 'none', 'l2', 'l2', 'none', 'none'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_solver': masked_array(data=['sag', 'newton-cg', 'sag', 'newton-cg', 'sag',\n",
      "                   'newton-cg', 'sag', 'newton-cg', 'sag', 'newton-cg',\n",
      "                   'sag', 'newton-cg', 'sag', 'newton-cg', 'sag',\n",
      "                   'newton-cg'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'class_weight': 'balanced', 'fit_intercept': 0, 'penalty': 'l2', 'solver': 'sag'}, {'class_weight': 'balanced', 'fit_intercept': 0, 'penalty': 'l2', 'solver': 'newton-cg'}, {'class_weight': 'balanced', 'fit_intercept': 0, 'penalty': 'none', 'solver': 'sag'}, {'class_weight': 'balanced', 'fit_intercept': 0, 'penalty': 'none', 'solver': 'newton-cg'}, {'class_weight': 'balanced', 'fit_intercept': 1, 'penalty': 'l2', 'solver': 'sag'}, {'class_weight': 'balanced', 'fit_intercept': 1, 'penalty': 'l2', 'solver': 'newton-cg'}, {'class_weight': 'balanced', 'fit_intercept': 1, 'penalty': 'none', 'solver': 'sag'}, {'class_weight': 'balanced', 'fit_intercept': 1, 'penalty': 'none', 'solver': 'newton-cg'}, {'class_weight': 'None', 'fit_intercept': 0, 'penalty': 'l2', 'solver': 'sag'}, {'class_weight': 'None', 'fit_intercept': 0, 'penalty': 'l2', 'solver': 'newton-cg'}, {'class_weight': 'None', 'fit_intercept': 0, 'penalty': 'none', 'solver': 'sag'}, {'class_weight': 'None', 'fit_intercept': 0, 'penalty': 'none', 'solver': 'newton-cg'}, {'class_weight': 'None', 'fit_intercept': 1, 'penalty': 'l2', 'solver': 'sag'}, {'class_weight': 'None', 'fit_intercept': 1, 'penalty': 'l2', 'solver': 'newton-cg'}, {'class_weight': 'None', 'fit_intercept': 1, 'penalty': 'none', 'solver': 'sag'}, {'class_weight': 'None', 'fit_intercept': 1, 'penalty': 'none', 'solver': 'newton-cg'}], 'split0_test_score': array([0.12138728, 0.12138728, 0.10982659, 0.15028902, 0.13294798,\n",
      "       0.15606936, 0.10404624, 0.13872832, 0.14450867, 0.14450867,\n",
      "       0.13294798, 0.16184971, 0.16184971, 0.19075145, 0.14450867,\n",
      "       0.13872832]), 'split1_test_score': array([0.16167665, 0.16167665, 0.1257485 , 0.16167665, 0.16766467,\n",
      "       0.16167665, 0.13772455, 0.16167665, 0.1497006 , 0.1497006 ,\n",
      "       0.16766467, 0.15568862, 0.1497006 , 0.18562874, 0.15568862,\n",
      "       0.15568862]), 'split2_test_score': array([0.15625, 0.15625, 0.1625 , 0.175  , 0.1625 , 0.1625 , 0.15   ,\n",
      "       0.18125, 0.175  , 0.175  , 0.15   , 0.1875 , 0.175  , 0.1875 ,\n",
      "       0.175  , 0.2    ]), 'mean_test_score': array([0.146, 0.146, 0.132, 0.162, 0.154, 0.16 , 0.13 , 0.16 , 0.156,\n",
      "       0.156, 0.15 , 0.168, 0.162, 0.188, 0.158, 0.164]), 'std_test_score': array([0.01803621, 0.01803621, 0.02192824, 0.01007809, 0.01545408,\n",
      "       0.0028783 , 0.01951907, 0.0173781 , 0.01320846, 0.01320846,\n",
      "       0.01431183, 0.01361588, 0.01022809, 0.00213949, 0.01253961,\n",
      "       0.02566647]), 'rank_test_score': array([13, 13, 15,  4, 11,  6, 16,  6,  9,  9, 12,  2,  4,  1,  8,  3],\n",
      "      dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Test with solver saga\n",
    "parameters_saga = {'penalty':('l2', 'elasticnet', 'none'),\n",
    "              'fit_intercept':[0, 1], 'class_weight':('balanced', 'None'),\n",
    "                  'l1_ratio':[0, 0.5, 1]}\n",
    "lg_saga = LogisticRegression(solver='saga')\n",
    "\n",
    "# Test with solver saga and l1 penalty\n",
    "parameters_saga_l1 = {'fit_intercept':[0, 1], 'class_weight':('balanced', 'None')}\n",
    "lg_saga_l1 = LogisticRegression(solver='saga', penalty='l1')\n",
    "\n",
    "\n",
    "# Test with solver lbfgs\n",
    "parameters_lbfgs = {'penalty':('l2', 'none'), 'fit_intercept':[0, 1],\n",
    "                   'class_weight':('balanced', 'None')}\n",
    "lg_lbfgs = LogisticRegression(solver='lbfgs')\n",
    "\n",
    "\n",
    "parameters = {'solver':('sag', 'newton-cg'), 'penalty':('l2', 'none'),\n",
    "              'fit_intercept':[0, 1], 'class_weight':('balanced', 'None')}\n",
    "lg = LogisticRegression()\n",
    "\n",
    "# Grid Search based on Logistic Regression with cross validation = 3 and all thread use\n",
    "# On Logistic Regression we modify the parameters because they can't be all used at the same time\n",
    "clf = GridSearchCV(lg, parameters, cv=3, n_jobs=-1)\n",
    "\n",
    "# Start of Grid Search\n",
    "clf.fit(X_dtm, y)\n",
    "                            \n",
    "print(clf.cv_results_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
