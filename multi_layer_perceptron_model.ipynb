{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "X = []\n",
    "with open(\"./data/train/crawler/data/tweets.txt.text\", newline='', encoding='utf8') as file_data:\n",
    "    i = 0 \n",
    "    for row in file_data:\n",
    "        if i < 500:\n",
    "            i = i +1\n",
    "            X.append(row)\n",
    "\n",
    "y = []\n",
    "with open(\"./data/train/crawler/data/tweets.txt.labels\", newline='', encoding='utf8') as file_data:\n",
    "    j = 0\n",
    "    for row in file_data:\n",
    "        if j < 500:\n",
    "            j = j +1\n",
    "            y.append(row.replace(\"\\n\",\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "X_dtm = vect.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=[]\n",
    "with open(\"./data/test/us_test.text\", newline='', encoding='utf8') as test_data:\n",
    "    file = test_data.readlines()\n",
    "    for row in file:\n",
    "        test.append(row.replace(\"\\n\",\"\"))\n",
    "\n",
    "test = np.asarray(test)\n",
    "test_dtm = vect.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1)\n",
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "test_label = []\n",
    "with open(\"./data/test/us_test.labels\", newline='', encoding='utf8') as test_data_label:\n",
    "    file = test_data_label.readlines()\n",
    "    for row in file:\n",
    "        test_label.append(row.replace(\"\\n\",\"\"))\n",
    "test_label = np.asarray(test_label)\n",
    "test_label = test_label.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.57      0.34     10798\n",
      "           1       0.13      0.10      0.11      4830\n",
      "          10       0.05      0.01      0.01      1432\n",
      "          11       0.27      0.08      0.12      1949\n",
      "          12       0.18      0.05      0.08      1265\n",
      "          13       0.02      0.00      0.00      1114\n",
      "          14       0.05      0.00      0.01      1306\n",
      "          15       0.06      0.03      0.04      1244\n",
      "          16       0.02      0.00      0.01      1153\n",
      "          17       0.62      0.12      0.21      1545\n",
      "          18       0.14      0.01      0.02      2417\n",
      "          19       0.05      0.00      0.00      1010\n",
      "           2       0.15      0.28      0.20      4534\n",
      "           3       0.08      0.08      0.08      2605\n",
      "           4       0.27      0.15      0.19      3716\n",
      "           5       0.05      0.05      0.05      1613\n",
      "           6       0.06      0.03      0.04      1996\n",
      "           7       0.14      0.01      0.02      2749\n",
      "           8       0.05      0.04      0.04      1549\n",
      "           9       0.04      0.05      0.04      1175\n",
      "\n",
      "    accuracy                           0.19     50000\n",
      "   macro avg       0.13      0.08      0.08     50000\n",
      "weighted avg       0.16      0.19      0.14     50000\n",
      "\n",
      "la matrice de confusion : \n",
      "[[[19931 19271]\n",
      "  [ 4623  6175]]\n",
      "\n",
      " [[41731  3439]\n",
      "  [ 4331   499]]\n",
      "\n",
      " [[48360   208]\n",
      "  [ 1421    11]]\n",
      "\n",
      " [[47640   411]\n",
      "  [ 1795   154]]\n",
      "\n",
      " [[48422   313]\n",
      "  [ 1198    67]]\n",
      "\n",
      " [[48746   140]\n",
      "  [ 1111     3]]\n",
      "\n",
      " [[48571   123]\n",
      "  [ 1300     6]]\n",
      "\n",
      " [[48208   548]\n",
      "  [ 1207    37]]\n",
      "\n",
      " [[48558   289]\n",
      "  [ 1148     5]]\n",
      "\n",
      " [[48339   116]\n",
      "  [ 1353   192]]\n",
      "\n",
      " [[47394   189]\n",
      "  [ 2385    32]]\n",
      "\n",
      " [[48970    20]\n",
      "  [ 1009     1]]\n",
      "\n",
      " [[38502  6964]\n",
      "  [ 3283  1251]]\n",
      "\n",
      " [[45280  2115]\n",
      "  [ 2409   196]]\n",
      "\n",
      " [[44791  1493]\n",
      "  [ 3174   542]]\n",
      "\n",
      " [[46843  1544]\n",
      "  [ 1533    80]]\n",
      "\n",
      " [[47260   744]\n",
      "  [ 1946    50]]\n",
      "\n",
      " [[47050   201]\n",
      "  [ 2716    33]]\n",
      "\n",
      " [[47398  1053]\n",
      "  [ 1492    57]]\n",
      "\n",
      " [[47450  1375]\n",
      "  [ 1122    53]]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score, f1_score, jaccard_score, classification_report\n",
    "\n",
    "models = [\n",
    "    MLPClassifier(solver = 'adam', activation = 'logistic', learning_rate = 'adaptive')\n",
    "]\n",
    "\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    model.fit(X_dtm, y)\n",
    "    predict_label = model.predict(test_dtm)\n",
    "    acc = accuracy_score(predict_label,test_label)\n",
    "    f1 = f1_score(predict_label, test_label, average = 'weighted')\n",
    "    cm = multilabel_confusion_matrix(test_label,predict_label)\n",
    "    jaccard = jaccard_score(test_label, predict_label, average='micro')\n",
    "    print(classification_report(test_label, predict_label))\n",
    "    print (\"la matrice de confusion : \")\n",
    "    print(cm)\n",
    "    entries.append((model_name, acc, f1, jaccard))\n",
    "    \n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'accuracy', 'f1', 'jaccard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      model_name  accuracy        f1   jaccard\n",
      "0  MLPClassifier   0.18888  0.234367  0.104289\n"
     ]
    }
   ],
   "source": [
    "print (cv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Adam works better ; Logistic works better\n",
    "parameters = {'solver':('lbfgs', 'adam'), 'activation':('relu', 'logistic'), 'alpha':[0.0001, 0.00001, 0.001], \n",
    "              'learning_rate':('adaptive'), }\n",
    "\n",
    "mlp = MLPClassifier()\n",
    "\n",
    "clf = GridSearchCV(mlp, parameters, cv=3, n_jobs=-1)\n",
    "\n",
    "clf.fit(X_dtm, y)\n",
    "                            \n",
    "print(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
