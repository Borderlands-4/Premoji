{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "X = []\n",
    "with open(\"./data/train/crawler/data/tweets.txt.text\", newline='', encoding='utf8') as file_data:\n",
    "    i = 0 \n",
    "    for row in file_data:\n",
    "        if i < 5000:\n",
    "            i = i + 1\n",
    "            X.append(row)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "y = []\n",
    "with open(\"./data/train/crawler/data/tweets.txt.labels\", newline='', encoding='utf8') as file_data:\n",
    "    j = 0\n",
    "    for row in file_data:\n",
    "        if j < 5000:\n",
    "            j = j + 1\n",
    "            y.append(row.replace(\"\\n\",\"\"))\n",
    "        else:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data vectorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "X_dtm = vect.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data test loading and vectorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=[]\n",
    "with open(\"./data/test/us_test.text\", newline='', encoding='utf8') as test_data:\n",
    "    file = test_data.readlines()\n",
    "    for row in file:\n",
    "        test.append(row.replace(\"\\n\",\"\"))\n",
    "\n",
    "test = np.asarray(test)\n",
    "test_dtm = vect.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = []\n",
    "with open(\"./data/test/us_test.labels\", newline='', encoding='utf8') as test_data_label:\n",
    "    file = test_data_label.readlines()\n",
    "    for row in file:\n",
    "        test_label.append(row.replace(\"\\n\",\"\"))\n",
    "test_label = np.asarray(test_label)\n",
    "test_label = test_label.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model implementation and training\n",
    "## Measurements calculation and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:568: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.50      0.36     10798\n",
      "           1       0.16      0.19      0.17      4830\n",
      "          10       0.12      0.07      0.08      1432\n",
      "          11       0.42      0.28      0.33      1949\n",
      "          12       0.26      0.19      0.22      1265\n",
      "          13       0.06      0.01      0.02      1114\n",
      "          14       0.05      0.02      0.03      1306\n",
      "          15       0.13      0.10      0.12      1244\n",
      "          16       0.06      0.02      0.03      1153\n",
      "          17       0.60      0.48      0.53      1545\n",
      "          18       0.18      0.05      0.07      2417\n",
      "          19       0.03      0.01      0.01      1010\n",
      "           2       0.24      0.31      0.27      4534\n",
      "           3       0.10      0.08      0.09      2605\n",
      "           4       0.44      0.23      0.30      3716\n",
      "           5       0.05      0.07      0.06      1613\n",
      "           6       0.10      0.07      0.08      1996\n",
      "           7       0.19      0.08      0.11      2749\n",
      "           8       0.06      0.05      0.05      1549\n",
      "           9       0.07      0.04      0.05      1175\n",
      "\n",
      "    accuracy                           0.23     50000\n",
      "   macro avg       0.18      0.14      0.15     50000\n",
      "weighted avg       0.22      0.23      0.21     50000\n",
      "\n",
      "la matrice de confusion : \n",
      "[[[24925 14277]\n",
      "  [ 5349  5449]]\n",
      "\n",
      " [[40155  5015]\n",
      "  [ 3896   934]]\n",
      "\n",
      " [[47849   719]\n",
      "  [ 1338    94]]\n",
      "\n",
      " [[47323   728]\n",
      "  [ 1413   536]]\n",
      "\n",
      " [[48025   710]\n",
      "  [ 1020   245]]\n",
      "\n",
      " [[48681   205]\n",
      "  [ 1101    13]]\n",
      "\n",
      " [[48142   552]\n",
      "  [ 1274    32]]\n",
      "\n",
      " [[47905   851]\n",
      "  [ 1116   128]]\n",
      "\n",
      " [[48444   403]\n",
      "  [ 1126    27]]\n",
      "\n",
      " [[47971   484]\n",
      "  [  808   737]]\n",
      "\n",
      " [[47073   510]\n",
      "  [ 2305   112]]\n",
      "\n",
      " [[48618   372]\n",
      "  [ 1000    10]]\n",
      "\n",
      " [[40883  4583]\n",
      "  [ 3111  1423]]\n",
      "\n",
      " [[45648  1747]\n",
      "  [ 2402   203]]\n",
      "\n",
      " [[45177  1107]\n",
      "  [ 2859   857]]\n",
      "\n",
      " [[46147  2240]\n",
      "  [ 1500   113]]\n",
      "\n",
      " [[46677  1327]\n",
      "  [ 1856   140]]\n",
      "\n",
      " [[46375   876]\n",
      "  [ 2538   211]]\n",
      "\n",
      " [[47227  1224]\n",
      "  [ 1473    76]]\n",
      "\n",
      " [[48143   682]\n",
      "  [ 1127    48]]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score, f1_score, jaccard_score, classification_report\n",
    "\n",
    "models = [\n",
    "    MLPClassifier(solver = 'adam', activation = 'logistic', learning_rate = 'adaptive')\n",
    "]\n",
    "\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    model.fit(X_dtm, y)\n",
    "    predict_label = model.predict(test_dtm)\n",
    "    acc = accuracy_score(predict_label,test_label)\n",
    "    f1 = f1_score(predict_label, test_label, average = 'weighted')\n",
    "    cm = multilabel_confusion_matrix(test_label,predict_label)\n",
    "    jaccard = jaccard_score(test_label, predict_label, average='micro')\n",
    "    print(classification_report(test_label, predict_label))\n",
    "    print (\"la matrice de confusion : \")\n",
    "    print(cm)\n",
    "    entries.append((model_name, acc, f1, jaccard))\n",
    "    \n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'accuracy', 'f1', 'jaccard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      model_name  accuracy        f1   jaccard\n",
      "0  MLPClassifier   0.22776  0.249888  0.128515\n"
     ]
    }
   ],
   "source": [
    "print (cv_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search use to find the best parameters for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Adam works better ; Logistic works better\n",
    "parameters = {'solver':('lbfgs', 'adam'), 'activation':('relu', 'logistic'), \n",
    "              'alpha':[0.0001, 0.00001, 0.001]\n",
    "               }\n",
    "\n",
    "mlp = MLPClassifier(learning_rate = 'adaptive')\n",
    "\n",
    "clf = GridSearchCV(mlp, parameters, cv=3, n_jobs=-1)\n",
    "\n",
    "clf.fit(X_dtm, y)\n",
    "                            \n",
    "print(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
