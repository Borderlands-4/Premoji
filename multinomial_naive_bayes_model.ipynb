{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "X = []\n",
    "with open(\"./data/train/crawler/data/tweets.txt.text\", newline='', encoding='utf8') as file_data:\n",
    "    i = 0 \n",
    "    for row in file_data:\n",
    "        X.append(row.replace(\"\\n\",\"\"))\n",
    "            \n",
    "y = []\n",
    "with open(\"./data/train/crawler/data/tweets.txt.labels\", newline='', encoding='utf8') as file_data:\n",
    "    j = 0\n",
    "    for row in file_data:\n",
    "        y.append(row.replace(\"\\n\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data vectorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "X_dtm = vect.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data test loading and vectorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test=[]\n",
    "with open(\"./data/test/us_test.text\", newline='', encoding='utf8') as test_data:\n",
    "    file = test_data.readlines()\n",
    "    for row in file:\n",
    "        test.append(row.replace(\"\\n\",\"\"))\n",
    "\n",
    "test = np.asarray(test)\n",
    "test_dtm = vect.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = []\n",
    "with open(\"./data/test/us_test.labels\", newline='', encoding='utf8') as test_data_label:\n",
    "    file = test_data_label.readlines()\n",
    "    for row in file:\n",
    "        test_label.append(row.replace(\"\\n\",\"\"))\n",
    "test_label = np.asarray(test_label)\n",
    "test_label = test_label.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model implementation and training\n",
    "## Measurements calculation and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.51      0.42     10798\n",
      "           1       0.24      0.25      0.24      4830\n",
      "          10       0.16      0.14      0.15      1432\n",
      "          11       0.46      0.47      0.47      1949\n",
      "          12       0.24      0.42      0.30      1265\n",
      "          13       0.20      0.06      0.10      1114\n",
      "          14       0.08      0.04      0.06      1306\n",
      "          15       0.22      0.14      0.17      1244\n",
      "          16       0.08      0.04      0.05      1153\n",
      "          17       0.59      0.55      0.57      1545\n",
      "          18       0.29      0.11      0.16      2417\n",
      "          19       0.05      0.02      0.03      1010\n",
      "           2       0.30      0.47      0.37      4534\n",
      "           3       0.15      0.09      0.11      2605\n",
      "           4       0.45      0.41      0.43      3716\n",
      "           5       0.08      0.08      0.08      1613\n",
      "           6       0.14      0.12      0.13      1996\n",
      "           7       0.27      0.19      0.22      2749\n",
      "           8       0.18      0.09      0.12      1549\n",
      "           9       0.11      0.06      0.08      1175\n",
      "\n",
      "    accuracy                           0.30     50000\n",
      "   macro avg       0.23      0.21      0.21     50000\n",
      "weighted avg       0.27      0.30      0.28     50000\n",
      "\n",
      "la matrice de confusion : \n",
      "[[[28957 10245]\n",
      "  [ 5251  5547]]\n",
      "\n",
      " [[41309  3861]\n",
      "  [ 3632  1198]]\n",
      "\n",
      " [[47515  1053]\n",
      "  [ 1232   200]]\n",
      "\n",
      " [[47004  1047]\n",
      "  [ 1041   908]]\n",
      "\n",
      " [[47067  1668]\n",
      "  [  738   527]]\n",
      "\n",
      " [[48606   280]\n",
      "  [ 1043    71]]\n",
      "\n",
      " [[48072   622]\n",
      "  [ 1250    56]]\n",
      "\n",
      " [[48122   634]\n",
      "  [ 1070   174]]\n",
      "\n",
      " [[48355   492]\n",
      "  [ 1110    43]]\n",
      "\n",
      " [[47869   586]\n",
      "  [  691   854]]\n",
      "\n",
      " [[46948   635]\n",
      "  [ 2154   263]]\n",
      "\n",
      " [[48571   419]\n",
      "  [  990    20]]\n",
      "\n",
      " [[40517  4949]\n",
      "  [ 2388  2146]]\n",
      "\n",
      " [[46106  1289]\n",
      "  [ 2380   225]]\n",
      "\n",
      " [[44457  1827]\n",
      "  [ 2199  1517]]\n",
      "\n",
      " [[46914  1473]\n",
      "  [ 1488   125]]\n",
      "\n",
      " [[46601  1403]\n",
      "  [ 1764   232]]\n",
      "\n",
      " [[45815  1436]\n",
      "  [ 2223   526]]\n",
      "\n",
      " [[47824   627]\n",
      "  [ 1407   142]]\n",
      "\n",
      " [[48218   607]\n",
      "  [ 1102    73]]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score, f1_score, jaccard_score, classification_report\n",
    "\n",
    "models = [\n",
    "    MultinomialNB(alpha=0.1)    \n",
    "]\n",
    "\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    model.fit(X_dtm, y)\n",
    "    predict_label = model.predict(test_dtm)\n",
    "    acc = accuracy_score(predict_label,test_label)\n",
    "    f1 = f1_score(predict_label, test_label, average = 'weighted')\n",
    "    cm = multilabel_confusion_matrix(test_label,predict_label)\n",
    "    jaccard = jaccard_score(test_label, predict_label, average='micro')\n",
    "    print(classification_report(test_label, predict_label))\n",
    "    print (\"la matrice de confusion : \")\n",
    "    print(cm)\n",
    "    entries.append((model_name, acc, f1, jaccard))\n",
    "    \n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'accuracy', 'f1', 'jaccard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      model_name  accuracy        f1   jaccard\n",
      "0  MultinomialNB   0.29694  0.318694  0.174357\n"
     ]
    }
   ],
   "source": [
    "print (cv_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search use to find the best parameters for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([1.27850437, 1.15368517, 1.31007473, 1.48485192, 1.31382211,\n",
      "       1.45402455, 1.34216412, 1.49965429, 1.41114871, 1.44537743,\n",
      "       1.34590165, 1.25690444]), 'std_fit_time': array([0.06269197, 0.02398118, 0.11619214, 0.18892382, 0.04715809,\n",
      "       0.10785702, 0.02873494, 0.10679886, 0.12807551, 0.22800635,\n",
      "       0.12273234, 0.05564568]), 'mean_score_time': array([0.24673923, 0.2404693 , 0.25699496, 0.24162793, 0.26615961,\n",
      "       0.24808971, 0.31336474, 0.27992964, 0.29836718, 0.25113853,\n",
      "       0.31259886, 0.20510936]), 'std_score_time': array([0.01003118, 0.01278984, 0.00108068, 0.04193019, 0.05757249,\n",
      "       0.0936216 , 0.10019844, 0.02738176, 0.03370489, 0.04558999,\n",
      "       0.02522813, 0.042204  ]), 'param_alpha': masked_array(data=[1, 1, 2, 2, 0.7, 0.7, 0, 0, 0.1, 0.1, 0.5, 0.5],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_fit_prior': masked_array(data=['False', 'True', 'False', 'True', 'False', 'True',\n",
      "                   'False', 'True', 'False', 'True', 'False', 'True'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'alpha': 1, 'fit_prior': 'False'}, {'alpha': 1, 'fit_prior': 'True'}, {'alpha': 2, 'fit_prior': 'False'}, {'alpha': 2, 'fit_prior': 'True'}, {'alpha': 0.7, 'fit_prior': 'False'}, {'alpha': 0.7, 'fit_prior': 'True'}, {'alpha': 0, 'fit_prior': 'False'}, {'alpha': 0, 'fit_prior': 'True'}, {'alpha': 0.1, 'fit_prior': 'False'}, {'alpha': 0.1, 'fit_prior': 'True'}, {'alpha': 0.5, 'fit_prior': 'False'}, {'alpha': 0.5, 'fit_prior': 'True'}], 'split0_test_score': array([0.33501325, 0.33501325, 0.29525733, 0.29525733, 0.35643833,\n",
      "       0.35643833, 0.41047353, 0.41047353, 0.4166188 , 0.4166188 ,\n",
      "       0.37567088, 0.37567088]), 'split1_test_score': array([0.34103318, 0.34103318, 0.296897  , 0.296897  , 0.36416978,\n",
      "       0.36416978, 0.44026237, 0.44026237, 0.44062678, 0.44062678,\n",
      "       0.3865405 , 0.3865405 ]), 'split2_test_score': array([0.3566624 , 0.3566624 , 0.30521121, 0.30521121, 0.38606926,\n",
      "       0.38606926, 0.50302345, 0.50302345, 0.49044169, 0.49044169,\n",
      "       0.41375285, 0.41375285]), 'mean_test_score': array([0.344236  , 0.344236  , 0.29912172, 0.29912172, 0.36889208,\n",
      "       0.36889208, 0.45125195, 0.45125195, 0.44922816, 0.44922816,\n",
      "       0.3919876 , 0.3919876 ]), 'std_test_score': array([0.00912377, 0.00912377, 0.00435752, 0.00435752, 0.01254918,\n",
      "       0.01254918, 0.03857414, 0.03857414, 0.03074562, 0.03074562,\n",
      "       0.0160169 , 0.0160169 ]), 'rank_test_score': array([ 9,  9, 11, 11,  7,  7,  1,  1,  3,  3,  5,  5], dtype=int32)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/.local/lib/python3.6/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Works better with small alpha, and fit_prior changes nothing\n",
    "parameters = {'alpha':[1, 2, 0.7, 0, 0.1, 0.5], 'fit_prior':('False', 'True')}\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "clf = GridSearchCV(mnb, parameters, cv=3, n_jobs=-1)\n",
    "\n",
    "clf.fit(X_dtm, y)\n",
    "                            \n",
    "print(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               model_name    score\n",
      "0      LogisticRegression  0.29528\n",
      "1  RandomForestClassifier  0.21596\n",
      "2               LinearSVC  0.24350\n",
      "3           MultinomialNB  0.26272\n"
     ]
    }
   ],
   "source": [
    "print (cv_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
