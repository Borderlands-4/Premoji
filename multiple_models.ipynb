{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "X = []\n",
    "with open(\"./data/train/crawler/data/tweets.txt.text\", newline='', encoding='utf8') as file_data:\n",
    "    i = 0 \n",
    "    for row in file_data:\n",
    "        if i < 500:\n",
    "            i = i +1\n",
    "            X.append(row)\n",
    "            \n",
    "y = []\n",
    "with open(\"./data/train/crawler/data/tweets.txt.labels\", newline='', encoding='utf8') as file_data:\n",
    "    j = 0\n",
    "    for row in file_data:\n",
    "        if j < 500:\n",
    "            j = j +1\n",
    "            y.append(row.replace(\"\\n\",\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "X_dtm = vect.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=[]\n",
    "with open(\"./data/test/us_test.text\", newline='', encoding='utf8') as test_data:\n",
    "    file = test_data.readlines()\n",
    "    for row in file:\n",
    "        test.append(row.replace(\"\\n\",\"\"))\n",
    "        \n",
    "test = np.asarray(test)\n",
    "test_dtm = vect.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1)\n",
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "test_label = []\n",
    "with open(\"./data/test/us_test.labels\", newline='', encoding='utf8') as test_data_label:\n",
    "    file = test_data_label.readlines()\n",
    "    for row in file:\n",
    "        test_label.append(row.replace(\"\\n\",\"\"))\n",
    "test_label = np.asarray(test_label)\n",
    "test_label = test_label.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/julien/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      1.00      0.36     10798\n",
      "           1       0.00      0.00      0.00      4830\n",
      "          10       0.00      0.00      0.00      1432\n",
      "          11       0.00      0.00      0.00      1949\n",
      "          12       0.00      0.00      0.00      1265\n",
      "          13       0.00      0.00      0.00      1114\n",
      "          14       0.00      0.00      0.00      1306\n",
      "          15       0.00      0.00      0.00      1244\n",
      "          16       0.00      0.00      0.00      1153\n",
      "          17       0.00      0.00      0.00      1545\n",
      "          18       0.00      0.00      0.00      2417\n",
      "          19       0.00      0.00      0.00      1010\n",
      "           2       0.00      0.00      0.00      4534\n",
      "           3       0.00      0.00      0.00      2605\n",
      "           4       0.00      0.00      0.00      3716\n",
      "           5       0.00      0.00      0.00      1613\n",
      "           6       0.00      0.00      0.00      1996\n",
      "           7       0.00      0.00      0.00      2749\n",
      "           8       0.00      0.00      0.00      1549\n",
      "           9       0.00      0.00      0.00      1175\n",
      "\n",
      "    accuracy                           0.22     50000\n",
      "   macro avg       0.01      0.05      0.02     50000\n",
      "weighted avg       0.05      0.22      0.08     50000\n",
      "\n",
      "la matrice de confusion : \n",
      "[[[    0 39202]\n",
      "  [    0 10798]]\n",
      "\n",
      " [[45170     0]\n",
      "  [ 4830     0]]\n",
      "\n",
      " [[48568     0]\n",
      "  [ 1432     0]]\n",
      "\n",
      " [[48051     0]\n",
      "  [ 1949     0]]\n",
      "\n",
      " [[48735     0]\n",
      "  [ 1265     0]]\n",
      "\n",
      " [[48886     0]\n",
      "  [ 1114     0]]\n",
      "\n",
      " [[48694     0]\n",
      "  [ 1306     0]]\n",
      "\n",
      " [[48756     0]\n",
      "  [ 1244     0]]\n",
      "\n",
      " [[48847     0]\n",
      "  [ 1153     0]]\n",
      "\n",
      " [[48455     0]\n",
      "  [ 1545     0]]\n",
      "\n",
      " [[47583     0]\n",
      "  [ 2417     0]]\n",
      "\n",
      " [[48990     0]\n",
      "  [ 1010     0]]\n",
      "\n",
      " [[45466     0]\n",
      "  [ 4534     0]]\n",
      "\n",
      " [[47395     0]\n",
      "  [ 2605     0]]\n",
      "\n",
      " [[46284     0]\n",
      "  [ 3716     0]]\n",
      "\n",
      " [[48387     0]\n",
      "  [ 1613     0]]\n",
      "\n",
      " [[48004     0]\n",
      "  [ 1996     0]]\n",
      "\n",
      " [[47251     0]\n",
      "  [ 2749     0]]\n",
      "\n",
      " [[48451     0]\n",
      "  [ 1549     0]]\n",
      "\n",
      " [[48825     0]\n",
      "  [ 1175     0]]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.80      0.36     10798\n",
      "           1       0.11      0.06      0.08      4830\n",
      "          10       0.06      0.00      0.00      1432\n",
      "          11       0.03      0.00      0.01      1949\n",
      "          12       0.07      0.01      0.01      1265\n",
      "          13       0.05      0.00      0.00      1114\n",
      "          14       0.11      0.00      0.00      1306\n",
      "          15       0.02      0.00      0.00      1244\n",
      "          16       0.04      0.00      0.00      1153\n",
      "          17       0.69      0.39      0.50      1545\n",
      "          18       0.13      0.00      0.00      2417\n",
      "          19       0.00      0.00      0.00      1010\n",
      "           2       0.16      0.21      0.18      4534\n",
      "           3       0.08      0.02      0.03      2605\n",
      "           4       0.20      0.05      0.08      3716\n",
      "           5       0.07      0.03      0.04      1613\n",
      "           6       0.09      0.01      0.02      1996\n",
      "           7       0.16      0.01      0.01      2749\n",
      "           8       0.05      0.02      0.03      1549\n",
      "           9       0.05      0.01      0.01      1175\n",
      "\n",
      "    accuracy                           0.22     50000\n",
      "   macro avg       0.12      0.08      0.07     50000\n",
      "weighted avg       0.15      0.22      0.13     50000\n",
      "\n",
      "la matrice de confusion : \n",
      "[[[10754 28448]\n",
      "  [ 2191  8607]]\n",
      "\n",
      " [[43075  2095]\n",
      "  [ 4559   271]]\n",
      "\n",
      " [[48520    48]\n",
      "  [ 1429     3]]\n",
      "\n",
      " [[47797   254]\n",
      "  [ 1941     8]]\n",
      "\n",
      " [[48612   123]\n",
      "  [ 1256     9]]\n",
      "\n",
      " [[48867    19]\n",
      "  [ 1113     1]]\n",
      "\n",
      " [[48677    17]\n",
      "  [ 1304     2]]\n",
      "\n",
      " [[48608   148]\n",
      "  [ 1241     3]]\n",
      "\n",
      " [[48824    23]\n",
      "  [ 1152     1]]\n",
      "\n",
      " [[48183   272]\n",
      "  [  935   610]]\n",
      "\n",
      " [[47556    27]\n",
      "  [ 2413     4]]\n",
      "\n",
      " [[48979    11]\n",
      "  [ 1010     0]]\n",
      "\n",
      " [[40636  4830]\n",
      "  [ 3593   941]]\n",
      "\n",
      " [[46739   656]\n",
      "  [ 2549    56]]\n",
      "\n",
      " [[45520   764]\n",
      "  [ 3522   194]]\n",
      "\n",
      " [[47834   553]\n",
      "  [ 1571    42]]\n",
      "\n",
      " [[47824   180]\n",
      "  [ 1979    17]]\n",
      "\n",
      " [[47154    97]\n",
      "  [ 2730    19]]\n",
      "\n",
      " [[47977   474]\n",
      "  [ 1522    27]]\n",
      "\n",
      " [[48687   138]\n",
      "  [ 1167     8]]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.83      0.37     10798\n",
      "           1       0.12      0.05      0.07      4830\n",
      "          10       0.03      0.00      0.00      1432\n",
      "          11       0.30      0.02      0.04      1949\n",
      "          12       0.09      0.01      0.02      1265\n",
      "          13       0.05      0.00      0.00      1114\n",
      "          14       0.20      0.00      0.00      1306\n",
      "          15       0.02      0.00      0.01      1244\n",
      "          16       0.00      0.00      0.00      1153\n",
      "          17       0.66      0.56      0.61      1545\n",
      "          18       0.31      0.00      0.01      2417\n",
      "          19       0.14      0.00      0.00      1010\n",
      "           2       0.18      0.24      0.21      4534\n",
      "           3       0.12      0.04      0.05      2605\n",
      "           4       0.41      0.09      0.14      3716\n",
      "           5       0.07      0.01      0.02      1613\n",
      "           6       0.07      0.01      0.01      1996\n",
      "           7       0.19      0.01      0.01      2749\n",
      "           8       0.11      0.01      0.02      1549\n",
      "           9       0.04      0.01      0.01      1175\n",
      "\n",
      "    accuracy                           0.23     50000\n",
      "   macro avg       0.17      0.09      0.08     50000\n",
      "weighted avg       0.19      0.23      0.14     50000\n",
      "\n",
      "la matrice de confusion : \n",
      "[[[10255 28947]\n",
      "  [ 1872  8926]]\n",
      "\n",
      " [[43454  1716]\n",
      "  [ 4602   228]]\n",
      "\n",
      " [[48529    39]\n",
      "  [ 1431     1]]\n",
      "\n",
      " [[47954    97]\n",
      "  [ 1908    41]]\n",
      "\n",
      " [[48596   139]\n",
      "  [ 1251    14]]\n",
      "\n",
      " [[48867    19]\n",
      "  [ 1113     1]]\n",
      "\n",
      " [[48690     4]\n",
      "  [ 1305     1]]\n",
      "\n",
      " [[48574   182]\n",
      "  [ 1240     4]]\n",
      "\n",
      " [[48837    10]\n",
      "  [ 1153     0]]\n",
      "\n",
      " [[48005   450]\n",
      "  [  675   870]]\n",
      "\n",
      " [[47563    20]\n",
      "  [ 2408     9]]\n",
      "\n",
      " [[48984     6]\n",
      "  [ 1009     1]]\n",
      "\n",
      " [[40657  4809]\n",
      "  [ 3454  1080]]\n",
      "\n",
      " [[46707   688]\n",
      "  [ 2512    93]]\n",
      "\n",
      " [[45816   468]\n",
      "  [ 3394   322]]\n",
      "\n",
      " [[48169   218]\n",
      "  [ 1597    16]]\n",
      "\n",
      " [[47832   172]\n",
      "  [ 1983    13]]\n",
      "\n",
      " [[47173    78]\n",
      "  [ 2731    18]]\n",
      "\n",
      " [[48334   117]\n",
      "  [ 1534    15]]\n",
      "\n",
      " [[48664   161]\n",
      "  [ 1168     7]]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score, f1_score, jaccard_score, classification_report\n",
    "\n",
    "models = [\n",
    "    #LogisticRegression(random_state=0, solver='lbfgs',\n",
    "     #                     multi_class='multinomial',\n",
    "     #                   n_jobs=-1, max_iter= 1000),\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    RandomForestClassifier(n_estimators=200, random_state=0, criterion='entropy'),\n",
    "    RandomForestClassifier(n_estimators=200)\n",
    "    #LinearSVC(),\n",
    "    #MultinomialNB(),\n",
    "]\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    model.fit(X_dtm, y)\n",
    "    predict_label = model.predict(test_dtm)\n",
    "    acc = accuracy_score(predict_label,test_label)\n",
    "    f1 = f1_score(predict_label, test_label, average = 'weighted')\n",
    "    cm = multilabel_confusion_matrix(test_label,predict_label)\n",
    "    jaccard = jaccard_score(test_label, predict_label, average='micro')\n",
    "    print(classification_report(test_label, predict_label))\n",
    "    print (\"la matrice de confusion : \")\n",
    "    print(cm)\n",
    "    entries.append((model_name, acc, f1, jaccard))\n",
    "    \n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'accuracy', 'f1', 'jaccard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               model_name  accuracy        f1   jaccard\n",
      "0  RandomForestClassifier   0.21596  0.355209  0.121051\n",
      "1  RandomForestClassifier   0.21646  0.303113  0.121365\n",
      "2  RandomForestClassifier   0.23320  0.324431  0.131990\n"
     ]
    }
   ],
   "source": [
    "print (cv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# Adam works better ; Logistic works better\n",
    "#parameters = {'solver':('lbfgs', 'adam'), 'activation':('relu', 'logistic'), 'alpha':[0.0001, 0.00001, 0.001], \n",
    "#              'learning_rate':('adaptive'), }\n",
    "\n",
    "# Gini works better than entropy and more estimators, better the score is\n",
    "# parameters = {'n_estimators':[200, 300], 'criterion':('entropy', 'gini')}\n",
    "\n",
    "# Best with 'alpha': 0.001, 'loss': 'log', 'penalty': 'l2'\n",
    "parameters = {'loss':('hinge', 'log', 'modified_huber'), 'penalty':('l2', 'elasticnet'), 'alpha':[0.0001, 0.001], }\n",
    "sgd = SGDClassifier(l1_ratio=0.15, fit_intercept=True, max_iter=1000, \n",
    "                    tol=0.001, epsilon=0.1, n_jobs=-1, validation_fraction=0.1, \n",
    "                    n_iter_no_change=5)\n",
    "\n",
    "rdf = RandomForestClassifier()\n",
    "mlp = MLPClassifier()\n",
    "\n",
    "clf = GridSearchCV(sgd, parameters, cv=3, n_jobs=-1)\n",
    "\n",
    "clf.fit(X_dtm, y)\n",
    "                            \n",
    "print(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
