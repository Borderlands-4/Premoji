{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "X = []\n",
    "with open(\"./data/train/crawler/data/tweets.txt.text\", newline='', encoding='utf8') as file_data:\n",
    "    i = 0 \n",
    "    for row in file_data:\n",
    "        X.append(row.replace(\"\\n\",\"\"))\n",
    "            \n",
    "y = []\n",
    "with open(\"./data/train/crawler/data/tweets.txt.labels\", newline='', encoding='utf8') as file_data:\n",
    "    j = 0\n",
    "    for row in file_data:\n",
    "        y.append(row.replace(\"\\n\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data vectorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "X_dtm = vect.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data test loading and vectorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test=[]\n",
    "with open(\"./data/test/us_test.text\", newline='', encoding='utf8') as test_data:\n",
    "    file = test_data.readlines()\n",
    "    for row in file:\n",
    "        test.append(row.replace(\"\\n\",\"\"))\n",
    "\n",
    "test = np.asarray(test)\n",
    "test_dtm = vect.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = []\n",
    "with open(\"./data/test/us_test.labels\", newline='', encoding='utf8') as test_data_label:\n",
    "    file = test_data_label.readlines()\n",
    "    for row in file:\n",
    "        test_label.append(row.replace(\"\\n\",\"\"))\n",
    "test_label = np.asarray(test_label)\n",
    "test_label = test_label.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model implementation and training\n",
    "## Measurements calculation and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.95      0.36     10798\n",
      "           1       0.16      0.01      0.01      4830\n",
      "          10       0.11      0.00      0.01      1432\n",
      "          11       0.56      0.05      0.10      1949\n",
      "          12       0.47      0.13      0.20      1265\n",
      "          13       0.21      0.01      0.02      1114\n",
      "          14       0.07      0.00      0.00      1306\n",
      "          15       0.03      0.00      0.00      1244\n",
      "          16       0.10      0.00      0.01      1153\n",
      "          17       0.65      0.49      0.56      1545\n",
      "          18       0.23      0.01      0.01      2417\n",
      "          19       0.02      0.00      0.00      1010\n",
      "           2       0.30      0.06      0.10      4534\n",
      "           3       0.09      0.00      0.01      2605\n",
      "           4       0.56      0.13      0.21      3716\n",
      "           5       0.05      0.00      0.01      1613\n",
      "           6       0.20      0.01      0.02      1996\n",
      "           7       0.20      0.01      0.01      2749\n",
      "           8       0.06      0.00      0.00      1549\n",
      "           9       0.10      0.00      0.01      1175\n",
      "\n",
      "    accuracy                           0.24     50000\n",
      "   macro avg       0.22      0.09      0.08     50000\n",
      "weighted avg       0.24      0.24      0.13     50000\n",
      "\n",
      "la matrice de confusion : \n",
      "[[[ 3905 35297]\n",
      "  [  559 10239]]\n",
      "\n",
      " [[45000   170]\n",
      "  [ 4797    33]]\n",
      "\n",
      " [[48526    42]\n",
      "  [ 1427     5]]\n",
      "\n",
      " [[47969    82]\n",
      "  [ 1846   103]]\n",
      "\n",
      " [[48549   186]\n",
      "  [ 1102   163]]\n",
      "\n",
      " [[48838    48]\n",
      "  [ 1101    13]]\n",
      "\n",
      " [[48667    27]\n",
      "  [ 1304     2]]\n",
      "\n",
      " [[48726    30]\n",
      "  [ 1243     1]]\n",
      "\n",
      " [[48809    38]\n",
      "  [ 1149     4]]\n",
      "\n",
      " [[48037   418]\n",
      "  [  781   764]]\n",
      "\n",
      " [[47530    53]\n",
      "  [ 2401    16]]\n",
      "\n",
      " [[48948    42]\n",
      "  [ 1009     1]]\n",
      "\n",
      " [[44803   663]\n",
      "  [ 4256   278]]\n",
      "\n",
      " [[47310    85]\n",
      "  [ 2597     8]]\n",
      "\n",
      " [[45912   372]\n",
      "  [ 3248   468]]\n",
      "\n",
      " [[48295    92]\n",
      "  [ 1608     5]]\n",
      "\n",
      " [[47937    67]\n",
      "  [ 1979    17]]\n",
      "\n",
      " [[47192    59]\n",
      "  [ 2734    15]]\n",
      "\n",
      " [[48400    51]\n",
      "  [ 1546     3]]\n",
      "\n",
      " [[48789    36]\n",
      "  [ 1171     4]]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score, f1_score, jaccard_score, classification_report\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=3, max_depth=50, criterion='gini')    \n",
    "]\n",
    "\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    model.fit(X_dtm, y)\n",
    "    predict_label = model.predict(test_dtm)\n",
    "    acc = accuracy_score(predict_label,test_label)\n",
    "    f1 = f1_score(predict_label, test_label, average = 'weighted')\n",
    "    cm = multilabel_confusion_matrix(test_label,predict_label)\n",
    "    jaccard = jaccard_score(test_label, predict_label, average='micro')\n",
    "    print(classification_report(test_label, predict_label))\n",
    "    print (\"la matrice de confusion : \")\n",
    "    print(cm)\n",
    "    entries.append((model_name, acc, f1, jaccard))\n",
    "    \n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'accuracy', 'f1', 'jaccard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               model_name  accuracy        f1  jaccard\n",
      "0  RandomForestClassifier   0.24284  0.351621   0.1382\n"
     ]
    }
   ],
   "source": [
    "print (cv_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search use to find the best parameters for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([1.15674965, 2.13355851, 1.41043146, 1.8539598 ]), 'std_fit_time': array([0.03226974, 0.30035809, 0.03162175, 0.05005567]), 'mean_score_time': array([0.03836799, 0.07133683, 0.06487362, 0.0717663 ]), 'std_score_time': array([0.00107693, 0.01531819, 0.01782814, 0.01722672]), 'param_criterion': masked_array(data=['entropy', 'entropy', 'gini', 'gini'],\n",
      "             mask=[False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_n_estimators': masked_array(data=[200, 300, 200, 300],\n",
      "             mask=[False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'criterion': 'entropy', 'n_estimators': 200}, {'criterion': 'entropy', 'n_estimators': 300}, {'criterion': 'gini', 'n_estimators': 200}, {'criterion': 'gini', 'n_estimators': 300}], 'split0_test_score': array([0.1849711 , 0.1734104 , 0.20231214, 0.19075145]), 'split1_test_score': array([0.17964072, 0.17365269, 0.20359281, 0.19760479]), 'split2_test_score': array([0.20625, 0.1875 , 0.225  , 0.2375 ]), 'mean_test_score': array([0.19 , 0.178, 0.21 , 0.208]), 'std_test_score': array([0.01136193, 0.00651771, 0.01030345, 0.0204331 ]), 'rank_test_score': array([3, 4, 1, 2], dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Gini works better than entropy and more estimators, better the score is\n",
    "parameters = {'n_estimators':[200, 300], 'criterion':('entropy', 'gini')}\n",
    "rdf = RandomForestClassifier()\n",
    "\n",
    "clf = GridSearchCV(rdf, parameters, cv=3, n_jobs=-1)\n",
    "\n",
    "clf.fit(X_dtm, y)\n",
    "                            \n",
    "print(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               model_name    score\n",
      "0      LogisticRegression  0.29528\n",
      "1  RandomForestClassifier  0.21596\n",
      "2               LinearSVC  0.24350\n",
      "3           MultinomialNB  0.26272\n"
     ]
    }
   ],
   "source": [
    "print (cv_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
