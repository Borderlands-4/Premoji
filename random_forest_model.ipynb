{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "X = []\n",
    "with open(\"./data/train/crawler/data/tweets.txt.text\", newline='', encoding='utf8') as file_data:\n",
    "    i = 0 \n",
    "    for row in file_data:\n",
    "        if i < 500:\n",
    "            i = i +1\n",
    "            X.append(row)\n",
    "            \n",
    "y = []\n",
    "with open(\"./data/train/crawler/data/tweets.txt.labels\", newline='', encoding='utf8') as file_data:\n",
    "    j = 0\n",
    "    for row in file_data:\n",
    "        if j < 500:\n",
    "            j = j +1\n",
    "            y.append(row.replace(\"\\n\",\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "X_dtm = vect.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test=[]\n",
    "with open(\"./data/test/us_test.text\", newline='', encoding='utf8') as test_data:\n",
    "    file = test_data.readlines()\n",
    "    for row in file:\n",
    "        test.append(row.replace(\"\\n\",\"\"))\n",
    "\n",
    "test = np.asarray(test)\n",
    "test_dtm = vect.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = []\n",
    "with open(\"./data/test/us_test.labels\", newline='', encoding='utf8') as test_data_label:\n",
    "    file = test_data_label.readlines()\n",
    "    for row in file:\n",
    "        test_label.append(row.replace(\"\\n\",\"\"))\n",
    "test_label = np.asarray(test_label)\n",
    "test_label = test_label.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "models = [\n",
    "    #RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    #RandomForestClassifier(n_estimators=200, random_state=0, criterion='entropy'),\n",
    "    RandomForestClassifier(n_estimators=200)    \n",
    "]\n",
    "\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    model.fit(X_dtm, y)\n",
    "    model.predict(test_dtm)\n",
    "    score = model.score(test_dtm, test_label)\n",
    "    entries.append((model_name, score))\n",
    "    \n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               model_name    score\n",
      "0  RandomForestClassifier  0.23544\n"
     ]
    }
   ],
   "source": [
    "print (cv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.11071221, 0.10626809, 0.1133581 , 0.10673277, 0.11141555,\n",
      "       0.10824871, 0.10428945, 0.10516866, 0.10816121, 0.10662842,\n",
      "       0.10634478, 0.10543187]), 'std_fit_time': array([0.00759397, 0.00174278, 0.00459301, 0.00163899, 0.00081651,\n",
      "       0.00113899, 0.00122334, 0.00122331, 0.00314407, 0.0024877 ,\n",
      "       0.00162848, 0.00162532]), 'mean_score_time': array([0.00137814, 0.00140174, 0.00094024, 0.0014178 , 0.00064158,\n",
      "       0.00102043, 0.00147176, 0.0007232 , 0.00146397, 0.00157015,\n",
      "       0.00086896, 0.00137337]), 'std_score_time': array([5.05210801e-04, 6.37469439e-06, 3.78069242e-04, 1.78780376e-05,\n",
      "       2.38680695e-05, 2.41646610e-04, 6.72843505e-04, 5.45231314e-05,\n",
      "       1.27904007e-04, 4.57665162e-04, 1.72418050e-04, 1.19716413e-04]), 'param_alpha': masked_array(data=[0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_loss': masked_array(data=['hinge', 'hinge', 'log', 'log', 'modified_huber',\n",
      "                   'modified_huber', 'hinge', 'hinge', 'log', 'log',\n",
      "                   'modified_huber', 'modified_huber'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_penalty': masked_array(data=['l2', 'elasticnet', 'l2', 'elasticnet', 'l2',\n",
      "                   'elasticnet', 'l2', 'elasticnet', 'l2', 'elasticnet',\n",
      "                   'l2', 'elasticnet'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'alpha': 0.0001, 'loss': 'hinge', 'penalty': 'l2'}, {'alpha': 0.0001, 'loss': 'hinge', 'penalty': 'elasticnet'}, {'alpha': 0.0001, 'loss': 'log', 'penalty': 'l2'}, {'alpha': 0.0001, 'loss': 'log', 'penalty': 'elasticnet'}, {'alpha': 0.0001, 'loss': 'modified_huber', 'penalty': 'l2'}, {'alpha': 0.0001, 'loss': 'modified_huber', 'penalty': 'elasticnet'}, {'alpha': 0.001, 'loss': 'hinge', 'penalty': 'l2'}, {'alpha': 0.001, 'loss': 'hinge', 'penalty': 'elasticnet'}, {'alpha': 0.001, 'loss': 'log', 'penalty': 'l2'}, {'alpha': 0.001, 'loss': 'log', 'penalty': 'elasticnet'}, {'alpha': 0.001, 'loss': 'modified_huber', 'penalty': 'l2'}, {'alpha': 0.001, 'loss': 'modified_huber', 'penalty': 'elasticnet'}], 'split0_test_score': array([0.10982659, 0.13294798, 0.13294798, 0.14450867, 0.12716763,\n",
      "       0.10404624, 0.13294798, 0.12138728, 0.14450867, 0.14450867,\n",
      "       0.12716763, 0.15606936]), 'split1_test_score': array([0.10179641, 0.08982036, 0.13173653, 0.14371257, 0.11377246,\n",
      "       0.10778443, 0.1497006 , 0.14371257, 0.16766467, 0.16167665,\n",
      "       0.15568862, 0.13772455]), 'split2_test_score': array([0.15   , 0.15625, 0.1875 , 0.175  , 0.15   , 0.1375 , 0.18125,\n",
      "       0.175  , 0.18125, 0.18125, 0.15625, 0.14375]), 'mean_test_score': array([0.12 , 0.126, 0.15 , 0.154, 0.13 , 0.116, 0.154, 0.146, 0.164,\n",
      "       0.162, 0.146, 0.146]), 'std_test_score': array([0.02084438, 0.02732614, 0.02572964, 0.01440962, 0.01478949,\n",
      "       0.01482917, 0.01992829, 0.02191961, 0.01520379, 0.0149824 ,\n",
      "       0.01369978, 0.00771848]), 'rank_test_score': array([11, 10,  5,  3,  9, 12,  3,  6,  1,  2,  6,  6], dtype=int32)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Gini works better than entropy and more estimators, better the score is\n",
    "parameters = {'n_estimators':[200, 300], 'criterion':('entropy', 'gini')}\n",
    "rdf = RandomForestClassifier()\n",
    "\n",
    "clf = GridSearchCV(rdf, parameters, cv=3, n_jobs=-1)\n",
    "\n",
    "clf.fit(X_dtm, y)\n",
    "                            \n",
    "print(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               model_name    score\n",
      "0      LogisticRegression  0.29528\n",
      "1  RandomForestClassifier  0.21596\n",
      "2               LinearSVC  0.24350\n",
      "3           MultinomialNB  0.26272\n"
     ]
    }
   ],
   "source": [
    "print (cv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
