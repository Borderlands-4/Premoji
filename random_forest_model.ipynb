{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "X = []\n",
    "with open(\"./data/train/crawler/data/tweets.txt.text\", newline='', encoding='utf8') as file_data:\n",
    "    i = 0 \n",
    "    for row in file_data:\n",
    "        if i < 500:\n",
    "            i = i +1\n",
    "            X.append(row)\n",
    "            \n",
    "y = []\n",
    "with open(\"./data/train/crawler/data/tweets.txt.labels\", newline='', encoding='utf8') as file_data:\n",
    "    j = 0\n",
    "    for row in file_data:\n",
    "        if j < 500:\n",
    "            j = j +1\n",
    "            y.append(row.replace(\"\\n\",\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "X_dtm = vect.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test=[]\n",
    "with open(\"./data/test/us_test.text\", newline='', encoding='utf8') as test_data:\n",
    "    file = test_data.readlines()\n",
    "    for row in file:\n",
    "        test.append(row.replace(\"\\n\",\"\"))\n",
    "\n",
    "test = np.asarray(test)\n",
    "test_dtm = vect.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = []\n",
    "with open(\"./data/test/us_test.labels\", newline='', encoding='utf8') as test_data_label:\n",
    "    file = test_data_label.readlines()\n",
    "    for row in file:\n",
    "        test_label.append(row.replace(\"\\n\",\"\"))\n",
    "test_label = np.asarray(test_label)\n",
    "test_label = test_label.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.87      0.37     10798\n",
      "           1       0.14      0.04      0.06      4830\n",
      "          10       0.02      0.00      0.00      1432\n",
      "          11       0.28      0.01      0.02      1949\n",
      "          12       0.06      0.01      0.01      1265\n",
      "          13       0.14      0.00      0.00      1114\n",
      "          14       0.00      0.00      0.00      1306\n",
      "          15       0.02      0.00      0.01      1244\n",
      "          16       0.10      0.00      0.00      1153\n",
      "          17       0.67      0.55      0.61      1545\n",
      "          18       0.13      0.00      0.00      2417\n",
      "          19       0.09      0.00      0.00      1010\n",
      "           2       0.19      0.20      0.20      4534\n",
      "           3       0.10      0.02      0.04      2605\n",
      "           4       0.44      0.08      0.13      3716\n",
      "           5       0.05      0.01      0.01      1613\n",
      "           6       0.07      0.00      0.01      1996\n",
      "           7       0.25      0.01      0.01      2749\n",
      "           8       0.10      0.00      0.01      1549\n",
      "           9       0.04      0.01      0.01      1175\n",
      "\n",
      "    accuracy                           0.23     50000\n",
      "   macro avg       0.16      0.09      0.07     50000\n",
      "weighted avg       0.19      0.23      0.14     50000\n",
      "\n",
      "la matrice de confusion : \n",
      "[[[ 8390 30812]\n",
      "  [ 1452  9346]]\n",
      "\n",
      " [[44096  1074]\n",
      "  [ 4655   175]]\n",
      "\n",
      " [[48526    42]\n",
      "  [ 1431     1]]\n",
      "\n",
      " [[48008    43]\n",
      "  [ 1932    17]]\n",
      "\n",
      " [[48628   107]\n",
      "  [ 1258     7]]\n",
      "\n",
      " [[48880     6]\n",
      "  [ 1113     1]]\n",
      "\n",
      " [[48681    13]\n",
      "  [ 1306     0]]\n",
      "\n",
      " [[48484   272]\n",
      "  [ 1239     5]]\n",
      "\n",
      " [[48838     9]\n",
      "  [ 1152     1]]\n",
      "\n",
      " [[48027   428]\n",
      "  [  689   856]]\n",
      "\n",
      " [[47557    26]\n",
      "  [ 2413     4]]\n",
      "\n",
      " [[48980    10]\n",
      "  [ 1009     1]]\n",
      "\n",
      " [[41638  3828]\n",
      "  [ 3608   926]]\n",
      "\n",
      " [[46826   569]\n",
      "  [ 2543    62]]\n",
      "\n",
      " [[45908   376]\n",
      "  [ 3420   296]]\n",
      "\n",
      " [[48146   241]\n",
      "  [ 1599    14]]\n",
      "\n",
      " [[47904   100]\n",
      "  [ 1988     8]]\n",
      "\n",
      " [[47207    44]\n",
      "  [ 2734    15]]\n",
      "\n",
      " [[48388    63]\n",
      "  [ 1542     7]]\n",
      "\n",
      " [[48637   188]\n",
      "  [ 1168     7]]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score, f1_score, jaccard_score, classification_report\n",
    "\n",
    "models = [\n",
    "    #RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    #RandomForestClassifier(n_estimators=200, random_state=0, criterion='entropy'),\n",
    "    RandomForestClassifier(n_estimators=200)    \n",
    "]\n",
    "\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    model.fit(X_dtm, y)\n",
    "    predict_label = model.predict(test_dtm)\n",
    "    acc = accuracy_score(predict_label,test_label)\n",
    "    f1 = f1_score(predict_label, test_label, average = 'weighted')\n",
    "    cm = multilabel_confusion_matrix(test_label,predict_label)\n",
    "    jaccard = jaccard_score(test_label, predict_label, average='micro')\n",
    "    print(classification_report(test_label, predict_label))\n",
    "    print (\"la matrice de confusion : \")\n",
    "    print(cm)\n",
    "    entries.append((model_name, acc, f1, jaccard))\n",
    "    \n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'accuracy', 'f1', 'jaccard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               model_name  accuracy        f1   jaccard\n",
      "0  RandomForestClassifier   0.23498  0.333096  0.133132\n"
     ]
    }
   ],
   "source": [
    "print (cv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([1.15674965, 2.13355851, 1.41043146, 1.8539598 ]), 'std_fit_time': array([0.03226974, 0.30035809, 0.03162175, 0.05005567]), 'mean_score_time': array([0.03836799, 0.07133683, 0.06487362, 0.0717663 ]), 'std_score_time': array([0.00107693, 0.01531819, 0.01782814, 0.01722672]), 'param_criterion': masked_array(data=['entropy', 'entropy', 'gini', 'gini'],\n",
      "             mask=[False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_n_estimators': masked_array(data=[200, 300, 200, 300],\n",
      "             mask=[False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'criterion': 'entropy', 'n_estimators': 200}, {'criterion': 'entropy', 'n_estimators': 300}, {'criterion': 'gini', 'n_estimators': 200}, {'criterion': 'gini', 'n_estimators': 300}], 'split0_test_score': array([0.1849711 , 0.1734104 , 0.20231214, 0.19075145]), 'split1_test_score': array([0.17964072, 0.17365269, 0.20359281, 0.19760479]), 'split2_test_score': array([0.20625, 0.1875 , 0.225  , 0.2375 ]), 'mean_test_score': array([0.19 , 0.178, 0.21 , 0.208]), 'std_test_score': array([0.01136193, 0.00651771, 0.01030345, 0.0204331 ]), 'rank_test_score': array([3, 4, 1, 2], dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Gini works better than entropy and more estimators, better the score is\n",
    "parameters = {'n_estimators':[200, 300], 'criterion':('entropy', 'gini')}\n",
    "rdf = RandomForestClassifier()\n",
    "\n",
    "clf = GridSearchCV(rdf, parameters, cv=3, n_jobs=-1)\n",
    "\n",
    "clf.fit(X_dtm, y)\n",
    "                            \n",
    "print(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               model_name    score\n",
      "0      LogisticRegression  0.29528\n",
      "1  RandomForestClassifier  0.21596\n",
      "2               LinearSVC  0.24350\n",
      "3           MultinomialNB  0.26272\n"
     ]
    }
   ],
   "source": [
    "print (cv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
