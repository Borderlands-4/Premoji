{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import library use to pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/julien/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/julien/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/julien/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/julien/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/julien/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/julien/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/julien/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/julien/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/julien/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/julien/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/julien/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/julien/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding, LSTM, Bidirectional\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/julien/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "X = []\n",
    "with open(\"./data/train/crawler/data/tweets.txt.text\", newline='', encoding='utf8') as file_data:\n",
    "    i = 0 \n",
    "    for row in file_data:\n",
    "        X.append(row)\n",
    "\n",
    "y = []\n",
    "with open(\"./data/train/crawler/data/tweets.txt.labels\", newline='', encoding='utf8') as file_data:\n",
    "    j = 0\n",
    "    for row in file_data:\n",
    "        y.append(row.replace(\"\\n\",\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dtm=[]\n",
    "with open(\"./data/test/us_test.text\", newline='', encoding='utf8') as test_data:\n",
    "    file = test_data.readlines()\n",
    "    for row in file:\n",
    "        test_dtm.append(row.replace(\"\\n\",\"\"))\n",
    "test_dtm = np.asarray(test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = []\n",
    "with open(\"./data/test/us_test.labels\", newline='', encoding='utf8') as test_data_label:\n",
    "    file = test_data_label.readlines()\n",
    "    for row in file:\n",
    "        test_label.append(row.replace(\"\\n\",\"\"))\n",
    "test_label = np.asarray(test_label)\n",
    "test_label = test_label.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets(tweets):\n",
    "  # Stripping away location for the end of tweets\n",
    "  p = re.compile(r'\\s*@ .*$')\n",
    "  tweets_1 = [p.sub('', tweet) for tweet in tweets]\n",
    "  \n",
    "  # Removing @user mentions\n",
    "  tweets_2 = [tweet.replace('@user', '') for tweet in tweets_1]\n",
    "  \n",
    "  # Removing stopwords\n",
    "  stop_words = set(stopwords.words('english'))\n",
    "\n",
    "  tweets_3 = []\n",
    "\n",
    "  for tweet in tweets_2:\n",
    "    res = ''\n",
    "    for w in tweet.split():\n",
    "      if w.lower() not in stop_words:\n",
    "        res = res+w+' '\n",
    "    tweets_3.append(res)\n",
    "    \n",
    "  # Removing unicode characters\n",
    "  tweets_4 = [(tweet.encode('ascii', 'ignore')).decode(\"utf-8\") for tweet in tweets_3]\n",
    "  \n",
    "  return tweets_4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = clean_tweets(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dtm = clean_tweets(test_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50000\n",
    "tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', num_words=vocab_size, oov_token=\"UNK\")\n",
    "tokenizer.fit_on_texts(texts=X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding and adding a padding to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train = tokenizer.texts_to_sequences(X)\n",
    "x_train = pad_sequences(tokenized_train, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving unified vector length after padding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = len(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding and adding a padding to the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_test = tokenizer.texts_to_sequences(test_dtm)\n",
    "x_test = pad_sequences(tokenized_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model implementation and training\n",
    "## Measurements calculation and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.50      0.32     10798\n",
      "           1       0.10      0.16      0.13      4830\n",
      "          10       0.04      0.06      0.05      1432\n",
      "          11       0.14      0.12      0.13      1949\n",
      "          12       0.10      0.11      0.10      1265\n",
      "          13       0.02      0.03      0.02      1114\n",
      "          14       0.03      0.03      0.03      1306\n",
      "          15       0.05      0.05      0.05      1244\n",
      "          16       0.03      0.03      0.03      1153\n",
      "          17       0.28      0.20      0.23      1545\n",
      "          18       0.08      0.03      0.04      2417\n",
      "          19       0.03      0.02      0.02      1010\n",
      "           2       0.12      0.08      0.10      4534\n",
      "           3       0.08      0.04      0.05      2605\n",
      "           4       0.16      0.04      0.07      3716\n",
      "           5       0.04      0.02      0.03      1613\n",
      "           6       0.08      0.02      0.04      1996\n",
      "           7       0.16      0.03      0.05      2749\n",
      "           8       0.06      0.01      0.02      1549\n",
      "           9       0.05      0.02      0.02      1175\n",
      "\n",
      "    accuracy                           0.16     50000\n",
      "   macro avg       0.10      0.08      0.08     50000\n",
      "weighted avg       0.13      0.16      0.13     50000\n",
      "\n",
      "la matrice de confusion : \n",
      "[[[22390 16812]\n",
      "  [ 5446  5352]]\n",
      "\n",
      " [[38378  6792]\n",
      "  [ 4054   776]]\n",
      "\n",
      " [[46516  2052]\n",
      "  [ 1348    84]]\n",
      "\n",
      " [[46597  1454]\n",
      "  [ 1708   241]]\n",
      "\n",
      " [[47486  1249]\n",
      "  [ 1131   134]]\n",
      "\n",
      " [[47774  1112]\n",
      "  [ 1086    28]]\n",
      "\n",
      " [[47477  1217]\n",
      "  [ 1264    42]]\n",
      "\n",
      " [[47681  1075]\n",
      "  [ 1182    62]]\n",
      "\n",
      " [[47908   939]\n",
      "  [ 1119    34]]\n",
      "\n",
      " [[47687   768]\n",
      "  [ 1240   305]]\n",
      "\n",
      " [[46742   841]\n",
      "  [ 2348    69]]\n",
      "\n",
      " [[48263   727]\n",
      "  [  990    20]]\n",
      "\n",
      " [[42766  2700]\n",
      "  [ 4159   375]]\n",
      "\n",
      " [[46349  1046]\n",
      "  [ 2513    92]]\n",
      "\n",
      " [[45476   808]\n",
      "  [ 3557   159]]\n",
      "\n",
      " [[47657   730]\n",
      "  [ 1579    34]]\n",
      "\n",
      " [[47442   562]\n",
      "  [ 1950    46]]\n",
      "\n",
      " [[46848   403]\n",
      "  [ 2670    79]]\n",
      "\n",
      " [[48108   343]\n",
      "  [ 1527    22]]\n",
      "\n",
      " [[48428   397]\n",
      "  [ 1156    19]]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score, f1_score, jaccard_score, classification_report\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=3, max_depth=50, criterion='gini')    \n",
    "]\n",
    "\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    model.fit(x_train, y)\n",
    "    predict_label = model.predict(x_test)\n",
    "    acc = accuracy_score(predict_label,test_label)\n",
    "    f1 = f1_score(predict_label, test_label, average = 'weighted')\n",
    "    cm = multilabel_confusion_matrix(test_label,predict_label)\n",
    "    jaccard = jaccard_score(test_label, predict_label, average='micro')\n",
    "    print(classification_report(test_label, predict_label))\n",
    "    print (\"la matrice de confusion : \")\n",
    "    print(cm)\n",
    "    entries.append((model_name, acc, f1, jaccard))\n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'accuracy', 'f1', 'jaccard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               model_name  accuracy        f1   jaccard\n",
      "0  RandomForestClassifier   0.15946  0.191684  0.086638\n"
     ]
    }
   ],
   "source": [
    "print (cv_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search use to find the best parameters for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/home/julien/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.20850412, 0.64488872, 0.36110107, 0.86796069, 0.34987028,\n",
      "       1.15327382, 0.43410603, 1.43390616, 0.1715188 , 0.88171991,\n",
      "       0.37534825, 1.22245971, 0.38801901, 1.01836991, 0.55536652,\n",
      "       1.2311546 ]), 'std_fit_time': array([0.02219167, 0.03748875, 0.02272539, 0.13014933, 0.00539448,\n",
      "       0.06817575, 0.07801177, 0.20012817, 0.03456551, 0.14927531,\n",
      "       0.06033472, 0.04752019, 0.08604417, 0.17173747, 0.05328032,\n",
      "       0.07199231]), 'mean_score_time': array([0.00069332, 0.00070977, 0.00068974, 0.0006427 , 0.00083105,\n",
      "       0.00107757, 0.00074188, 0.00067385, 0.00075984, 0.00184687,\n",
      "       0.00070278, 0.00712196, 0.00260623, 0.00085282, 0.00074792,\n",
      "       0.00102305]), 'std_score_time': array([9.11064746e-05, 8.17834808e-05, 5.54660213e-05, 4.02178215e-05,\n",
      "       9.68375409e-05, 2.26621956e-04, 1.56191689e-04, 2.94472416e-05,\n",
      "       1.10294988e-04, 1.46504840e-03, 8.47466172e-05, 6.12829924e-03,\n",
      "       2.61180159e-03, 1.95306295e-04, 9.56253696e-06, 4.53741605e-04]), 'param_class_weight': masked_array(data=['balanced', 'balanced', 'balanced', 'balanced',\n",
      "                   'balanced', 'balanced', 'balanced', 'balanced', 'None',\n",
      "                   'None', 'None', 'None', 'None', 'None', 'None', 'None'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_fit_intercept': masked_array(data=[0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_penalty': masked_array(data=['l2', 'l2', 'none', 'none', 'l2', 'l2', 'none', 'none',\n",
      "                   'l2', 'l2', 'none', 'none', 'l2', 'l2', 'none', 'none'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_solver': masked_array(data=['sag', 'newton-cg', 'sag', 'newton-cg', 'sag',\n",
      "                   'newton-cg', 'sag', 'newton-cg', 'sag', 'newton-cg',\n",
      "                   'sag', 'newton-cg', 'sag', 'newton-cg', 'sag',\n",
      "                   'newton-cg'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'class_weight': 'balanced', 'fit_intercept': 0, 'penalty': 'l2', 'solver': 'sag'}, {'class_weight': 'balanced', 'fit_intercept': 0, 'penalty': 'l2', 'solver': 'newton-cg'}, {'class_weight': 'balanced', 'fit_intercept': 0, 'penalty': 'none', 'solver': 'sag'}, {'class_weight': 'balanced', 'fit_intercept': 0, 'penalty': 'none', 'solver': 'newton-cg'}, {'class_weight': 'balanced', 'fit_intercept': 1, 'penalty': 'l2', 'solver': 'sag'}, {'class_weight': 'balanced', 'fit_intercept': 1, 'penalty': 'l2', 'solver': 'newton-cg'}, {'class_weight': 'balanced', 'fit_intercept': 1, 'penalty': 'none', 'solver': 'sag'}, {'class_weight': 'balanced', 'fit_intercept': 1, 'penalty': 'none', 'solver': 'newton-cg'}, {'class_weight': 'None', 'fit_intercept': 0, 'penalty': 'l2', 'solver': 'sag'}, {'class_weight': 'None', 'fit_intercept': 0, 'penalty': 'l2', 'solver': 'newton-cg'}, {'class_weight': 'None', 'fit_intercept': 0, 'penalty': 'none', 'solver': 'sag'}, {'class_weight': 'None', 'fit_intercept': 0, 'penalty': 'none', 'solver': 'newton-cg'}, {'class_weight': 'None', 'fit_intercept': 1, 'penalty': 'l2', 'solver': 'sag'}, {'class_weight': 'None', 'fit_intercept': 1, 'penalty': 'l2', 'solver': 'newton-cg'}, {'class_weight': 'None', 'fit_intercept': 1, 'penalty': 'none', 'solver': 'sag'}, {'class_weight': 'None', 'fit_intercept': 1, 'penalty': 'none', 'solver': 'newton-cg'}], 'split0_test_score': array([0.12138728, 0.12138728, 0.10982659, 0.15028902, 0.13294798,\n",
      "       0.15606936, 0.10404624, 0.13872832, 0.14450867, 0.14450867,\n",
      "       0.13294798, 0.16184971, 0.16184971, 0.19075145, 0.14450867,\n",
      "       0.13872832]), 'split1_test_score': array([0.16167665, 0.16167665, 0.1257485 , 0.16167665, 0.16766467,\n",
      "       0.16167665, 0.13772455, 0.16167665, 0.1497006 , 0.1497006 ,\n",
      "       0.16766467, 0.15568862, 0.1497006 , 0.18562874, 0.15568862,\n",
      "       0.15568862]), 'split2_test_score': array([0.15625, 0.15625, 0.1625 , 0.175  , 0.1625 , 0.1625 , 0.15   ,\n",
      "       0.18125, 0.175  , 0.175  , 0.15   , 0.1875 , 0.175  , 0.1875 ,\n",
      "       0.175  , 0.2    ]), 'mean_test_score': array([0.146, 0.146, 0.132, 0.162, 0.154, 0.16 , 0.13 , 0.16 , 0.156,\n",
      "       0.156, 0.15 , 0.168, 0.162, 0.188, 0.158, 0.164]), 'std_test_score': array([0.01803621, 0.01803621, 0.02192824, 0.01007809, 0.01545408,\n",
      "       0.0028783 , 0.01951907, 0.0173781 , 0.01320846, 0.01320846,\n",
      "       0.01431183, 0.01361588, 0.01022809, 0.00213949, 0.01253961,\n",
      "       0.02566647]), 'rank_test_score': array([13, 13, 15,  4, 11,  6, 16,  6,  9,  9, 12,  2,  4,  1,  8,  3],\n",
      "      dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Test with solver saga\n",
    "parameters_saga = {'penalty':('l2', 'elasticnet', 'none'),\n",
    "              'fit_intercept':[0, 1], 'class_weight':('balanced', 'None'),\n",
    "                  'l1_ratio':[0, 0.5, 1]}\n",
    "lg_saga = LogisticRegression(solver='saga')\n",
    "\n",
    "# Test with solver saga and l1 penalty\n",
    "parameters_saga_l1 = {'fit_intercept':[0, 1], 'class_weight':('balanced', 'None')}\n",
    "lg_saga_l1 = LogisticRegression(solver='saga', penalty='l1')\n",
    "\n",
    "\n",
    "# Test with solver lbfgs\n",
    "parameters_lbfgs = {'penalty':('l2', 'none'), 'fit_intercept':[0, 1],\n",
    "                   'class_weight':('balanced', 'None')}\n",
    "lg_lbfgs = LogisticRegression(solver='lbfgs')\n",
    "\n",
    "\n",
    "parameters = {'solver':('sag', 'newton-cg'), 'penalty':('l2', 'none'),\n",
    "              'fit_intercept':[0, 1], 'class_weight':('balanced', 'None')}\n",
    "lg = LogisticRegression()\n",
    "\n",
    "clf = GridSearchCV(lg, parameters, cv=3, n_jobs=-1)\n",
    "\n",
    "clf.fit(X_dtm, y)\n",
    "                            \n",
    "print(clf.cv_results_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
